{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Package"
      ],
      "metadata": {
        "id": "uFL_4EHCdTG9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DhVLKEvNdQav"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import scipy.io\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "SnvRm4SNdWje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt(\"data.txt\")\n",
        "data_label = np.argmax(data[:,27:34],-1)\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(data[:,0:27])\n",
        "data_scaler = scaler.transform(data[:,0:27])\n",
        "data_new = np.concatenate((np.expand_dims(data_label,axis=1), data_scaler), axis = 1)\n",
        "train, test = train_test_split(data_new, stratify = data_label, test_size = 0.2)\n",
        "dim = train.shape[1]"
      ],
      "metadata": {
        "id": "nW1xZjLoeqd0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distinguish the train/test and normal/abnormal"
      ],
      "metadata": {
        "id": "CVM1B48y1nte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_normal_train = train[train[:,0] == 0,1:dim]\n",
        "Y_normal_train = train[train[:,0] == 0,0]\n",
        "\n",
        "X_normal_test = test[test[:,0] == 0,1:dim]\n",
        "Y_normal_test = test[test[:,0] == 0,0]\n",
        "\n",
        "X_abnormal_train = train[train[:,0] == 1,1:dim]\n",
        "Y_abnormal_train = train[train[:,0] == 1,0]\n",
        "\n",
        "X_abnormal_test = test[test[:,0] == 1,1:dim]\n",
        "Y_abnormal_test = test[test[:,0] == 1,0]\n",
        "\n",
        "X_transition_train = train[train[:,0] == 5,1:dim]\n",
        "Y_transition_train = (train[train[:,0] == 5,0]+1)/3\n",
        "\n",
        "X_transition_test = test[test[:,0] == 5,1:dim]\n",
        "Y_transition_test = (test[test[:,0] == 5,0]+1)/3\n",
        "# 126,152,321"
      ],
      "metadata": {
        "id": "NTUJhf0XgLCx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_all = np.concatenate((X_normal_train,X_abnormal_train,X_transition_train))\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import manifold,datasets\n",
        "\n",
        "tsne = manifold.TSNE(n_components=2, init='pca', random_state=501)\n",
        "X_tsne = tsne.fit_transform(np.squeeze(X_train_all))\n",
        "print(\"Org data dimension is {}. Embedded data dimension is {}\".format(np.squeeze(X_train_all).shape[-1], X_tsne.shape[-1]))\n",
        "\n",
        "x_min, x_max = X_tsne.min(0), X_tsne.max(0)\n",
        "X_norm = (X_tsne - x_min) / (x_max - x_min)\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "plt.scatter(X_norm[0:126, 0], X_norm[0:126, 1],color = 'green', label = \"Z_Scratch\")\n",
        "plt.scatter(X_norm[126:278, 0], X_norm[126:278, 1],color = 'blue', label = \"Pastry\")\n",
        "plt.scatter(X_norm[278:599, 0], X_norm[278:599, 1],color = 'purple', label = \"Bumps\")\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "3EVSOpfWx8Lw",
        "outputId": "65728b1b-e4f1-4935-f5cb-0ba9b47de37d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Org data dimension is 27. Embedded data dimension is 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "Bn4sb0C5AQlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distinguish the type 1,2 and 3"
      ],
      "metadata": {
        "id": "MFT3v_fq17nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_teacher1 = np.concatenate((X_normal_train,X_abnormal_train))\n",
        "Y_teacher1 = np.concatenate((np.expand_dims(Y_normal_train, axis = 1), np.expand_dims(Y_abnormal_train, axis = 1)), axis = 0)\n",
        "Y_teacher1 = Y_teacher1.reshape(-1)\n",
        "Y_train1 = Y_teacher1 + 0\n",
        "\n",
        "X_test1 = np.concatenate((X_normal_test, X_abnormal_test))\n",
        "Y_test_teacher1 = np.concatenate((np.expand_dims(Y_normal_test, axis = 1), np.expand_dims(Y_abnormal_test, axis = 1)), axis = 0)\n",
        "Y_test_teacher1 = Y_test_teacher1.reshape(-1)\n",
        "Y_test1 = Y_test_teacher1 + 0"
      ],
      "metadata": {
        "id": "O-xtHyWqfn2Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_teacher2 = np.concatenate((X_normal_train,X_transition_train))\n",
        "Y_teacher2 = np.concatenate((np.expand_dims(Y_normal_train, axis = 1), np.expand_dims(Y_transition_train, axis = 1)), axis = 0)\n",
        "Y_teacher2 = Y_teacher2.reshape(-1)\n",
        "Y_train2 = Y_teacher2 + 0\n",
        "\n",
        "X_test2 = np.concatenate((X_normal_test, X_transition_test))\n",
        "Y_test_teacher2 = np.concatenate((np.expand_dims(Y_normal_test, axis = 1), np.expand_dims(Y_transition_test, axis = 1)), axis = 0)\n",
        "Y_test_teacher2 = Y_test_teacher2.reshape(-1)\n",
        "Y_test2 = Y_test_teacher2 + 0"
      ],
      "metadata": {
        "id": "Hq0owAMcpsim"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_teacher3 = np.concatenate((X_normal_train,X_abnormal_train,X_transition_train))\n",
        "Y_teacher3 = np.concatenate((np.expand_dims(Y_normal_train, axis = 1), np.expand_dims(Y_abnormal_train, axis = 1),np.expand_dims(Y_transition_train, axis = 1)), axis = 0)\n",
        "Y_teacher3 = Y_teacher3.reshape(-1)\n",
        "Y_train3 = Y_teacher3 + 0\n",
        "\n",
        "X_test3 = np.concatenate((X_normal_test, X_abnormal_test,X_transition_test))\n",
        "Y_test_teacher3 = np.concatenate((np.expand_dims(Y_normal_test, axis = 1), np.expand_dims(Y_abnormal_test, axis = 1),np.expand_dims(Y_transition_test, axis = 1)), axis = 0)\n",
        "Y_test_teacher3 = Y_test_teacher3.reshape(-1)\n",
        "Y_test3 = Y_test_teacher3 + 0"
      ],
      "metadata": {
        "id": "6lcWlTU3psyl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do the classification"
      ],
      "metadata": {
        "id": "Uj3eR6nW2EHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 1 and type 2 classification"
      ],
      "metadata": {
        "id": "S-wV8jFd-dLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='best_model.keras',  # File to save the best model\n",
        "                             monitor='val_loss',  # Monitor validation loss\n",
        "                             save_best_only=True,  # Save only the best model\n",
        "                             save_weights_only=False,  # Save the entire model (including architecture)\n",
        "                             mode='min',  # Mode can be 'min' for loss or 'max' for accuracy\n",
        "                             verbose=1)\n",
        "\n",
        "# Train the model\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "history  = model.fit(X_teacher1, Y_train1, epochs=epochs, batch_size=batch_size,\n",
        "          validation_data=(X_test1, Y_test1), callbacks=[checkpoint])\n",
        "\n",
        "print(model.summary())\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "#%% Evaluate the model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model.keras')\n",
        "\n",
        "predicted_labels = model.predict(X_test1)\n",
        "y_pred = np.argmax(predicted_labels, axis = 1).astype(int)\n",
        "#y_pred = (predicted_labels >= .5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_mat = confusion_matrix(Y_test_teacher1, y_pred)\n",
        "\n",
        "# Compute precision, recall, and F1-score\n",
        "classification_rep = classification_report(Y_test_teacher1, y_pred)\n",
        "del model\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wxruh2KVrIIw",
        "outputId": "e7407152-fd70-429a-8e20-b92c05e08467"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5625 - loss: 0.8361\n",
            "Epoch 1: val_loss improved from inf to 0.62155, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.6319 - loss: 0.8232 - val_accuracy: 0.8286 - val_loss: 0.6216\n",
            "Epoch 2/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 0.6562 - loss: 0.8168\n",
            "Epoch 2: val_loss improved from 0.62155 to 0.50391, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7514 - loss: 0.7005 - val_accuracy: 0.8857 - val_loss: 0.5039\n",
            "Epoch 3/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.6562 - loss: 0.6296\n",
            "Epoch 3: val_loss improved from 0.50391 to 0.40688, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8234 - loss: 0.5623 - val_accuracy: 0.9429 - val_loss: 0.4069\n",
            "Epoch 4/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7500 - loss: 0.5478\n",
            "Epoch 4: val_loss improved from 0.40688 to 0.33315, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8558 - loss: 0.4812 - val_accuracy: 0.9286 - val_loss: 0.3332\n",
            "Epoch 5/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8750 - loss: 0.4681\n",
            "Epoch 5: val_loss improved from 0.33315 to 0.27862, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9001 - loss: 0.4118 - val_accuracy: 0.9429 - val_loss: 0.2786\n",
            "Epoch 6/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.9062 - loss: 0.3332\n",
            "Epoch 6: val_loss improved from 0.27862 to 0.23717, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9287 - loss: 0.3233 - val_accuracy: 0.9571 - val_loss: 0.2372\n",
            "Epoch 7/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9062 - loss: 0.2666\n",
            "Epoch 7: val_loss improved from 0.23717 to 0.20746, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9370 - loss: 0.2762 - val_accuracy: 0.9714 - val_loss: 0.2075\n",
            "Epoch 8/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9375 - loss: 0.2224\n",
            "Epoch 8: val_loss improved from 0.20746 to 0.18479, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9301 - loss: 0.2515 - val_accuracy: 0.9714 - val_loss: 0.1848\n",
            "Epoch 9/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.9062 - loss: 0.2698\n",
            "Epoch 9: val_loss improved from 0.18479 to 0.16941, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9272 - loss: 0.2383 - val_accuracy: 0.9714 - val_loss: 0.1694\n",
            "Epoch 10/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.9375 - loss: 0.1560\n",
            "Epoch 10: val_loss improved from 0.16941 to 0.15505, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9284 - loss: 0.2070 - val_accuracy: 0.9714 - val_loss: 0.1551\n",
            "Epoch 11/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9375 - loss: 0.1664\n",
            "Epoch 11: val_loss improved from 0.15505 to 0.14232, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9243 - loss: 0.2030 - val_accuracy: 0.9714 - val_loss: 0.1423\n",
            "Epoch 12/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9688 - loss: 0.1281\n",
            "Epoch 12: val_loss improved from 0.14232 to 0.13122, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9507 - loss: 0.1719 - val_accuracy: 0.9714 - val_loss: 0.1312\n",
            "Epoch 13/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8750 - loss: 0.2889\n",
            "Epoch 13: val_loss improved from 0.13122 to 0.12462, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9285 - loss: 0.1953 - val_accuracy: 0.9714 - val_loss: 0.1246\n",
            "Epoch 14/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9688 - loss: 0.1270\n",
            "Epoch 14: val_loss improved from 0.12462 to 0.11723, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9529 - loss: 0.1427 - val_accuracy: 0.9714 - val_loss: 0.1172\n",
            "Epoch 15/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9062 - loss: 0.1853\n",
            "Epoch 15: val_loss improved from 0.11723 to 0.11046, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9343 - loss: 0.1583 - val_accuracy: 0.9857 - val_loss: 0.1105\n",
            "Epoch 16/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9375 - loss: 0.1504\n",
            "Epoch 16: val_loss improved from 0.11046 to 0.10257, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9423 - loss: 0.1437 - val_accuracy: 0.9857 - val_loss: 0.1026\n",
            "Epoch 17/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9062 - loss: 0.1900\n",
            "Epoch 17: val_loss improved from 0.10257 to 0.09796, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9395 - loss: 0.1503 - val_accuracy: 0.9857 - val_loss: 0.0980\n",
            "Epoch 18/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.1924\n",
            "Epoch 18: val_loss improved from 0.09796 to 0.09253, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9423 - loss: 0.1332 - val_accuracy: 0.9857 - val_loss: 0.0925\n",
            "Epoch 19/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9688 - loss: 0.1018\n",
            "Epoch 19: val_loss improved from 0.09253 to 0.08722, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9559 - loss: 0.1180 - val_accuracy: 0.9857 - val_loss: 0.0872\n",
            "Epoch 20/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0523\n",
            "Epoch 20: val_loss improved from 0.08722 to 0.08370, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9664 - loss: 0.0891 - val_accuracy: 0.9857 - val_loss: 0.0837\n",
            "Epoch 21/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9688 - loss: 0.0749\n",
            "Epoch 21: val_loss improved from 0.08370 to 0.07894, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1066 - val_accuracy: 0.9857 - val_loss: 0.0789\n",
            "Epoch 22/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9688 - loss: 0.0607\n",
            "Epoch 22: val_loss improved from 0.07894 to 0.07617, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.0890 - val_accuracy: 0.9857 - val_loss: 0.0762\n",
            "Epoch 23/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9688 - loss: 0.1022\n",
            "Epoch 23: val_loss improved from 0.07617 to 0.07261, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9696 - loss: 0.0973 - val_accuracy: 0.9857 - val_loss: 0.0726\n",
            "Epoch 24/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1053\n",
            "Epoch 24: val_loss improved from 0.07261 to 0.06785, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9716 - loss: 0.1030 - val_accuracy: 0.9857 - val_loss: 0.0679\n",
            "Epoch 25/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.9688 - loss: 0.1142\n",
            "Epoch 25: val_loss improved from 0.06785 to 0.06463, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9794 - loss: 0.0940 - val_accuracy: 0.9857 - val_loss: 0.0646\n",
            "Epoch 26/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0876\n",
            "Epoch 26: val_loss improved from 0.06463 to 0.06125, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9828 - loss: 0.0907 - val_accuracy: 0.9857 - val_loss: 0.0613\n",
            "Epoch 27/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 197ms/step - accuracy: 0.9688 - loss: 0.1347\n",
            "Epoch 27: val_loss improved from 0.06125 to 0.05955, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9731 - loss: 0.0935 - val_accuracy: 0.9857 - val_loss: 0.0595\n",
            "Epoch 28/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step - accuracy: 0.9375 - loss: 0.1238\n",
            "Epoch 28: val_loss improved from 0.05955 to 0.05646, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9694 - loss: 0.0886 - val_accuracy: 0.9857 - val_loss: 0.0565\n",
            "Epoch 29/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9688 - loss: 0.0674\n",
            "Epoch 29: val_loss improved from 0.05646 to 0.05356, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9828 - loss: 0.0698 - val_accuracy: 0.9857 - val_loss: 0.0536\n",
            "Epoch 30/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 179ms/step - accuracy: 1.0000 - loss: 0.0402\n",
            "Epoch 30: val_loss improved from 0.05356 to 0.05135, saving model to best_model.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9774 - loss: 0.0696 - val_accuracy: 0.9857 - val_loss: 0.0513\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_6 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                               \u001b[38;5;34m672\u001b[0m \n",
              "\n",
              " dense_7 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                               \u001b[38;5;34m300\u001b[0m \n",
              "\n",
              " dense_8 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                                 \u001b[38;5;34m39\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> \n",
              "\n",
              " dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> \n",
              "\n",
              " dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,035\u001b[0m (11.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,035</span> (11.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,011\u001b[0m (3.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,011</span> (3.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,024\u001b[0m (7.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,024</span> (7.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Confusion Matrix:\n",
            "[[31  1]\n",
            " [ 0 38]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.97      0.98        32\n",
            "         1.0       0.97      1.00      0.99        38\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.99      0.98      0.99        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 1,2, and 3 increment classification"
      ],
      "metadata": {
        "id": "pgykizvn-iXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model.keras')\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='best_model.keras',  # File to save the best model\n",
        "                             monitor='val_loss',  # Monitor validation loss\n",
        "                             save_best_only=True,  # Save only the best model\n",
        "                             save_weights_only=False,  # Save the entire model (including architecture)\n",
        "                             mode='min',  # Mode can be 'min' for loss or 'max' for accuracy\n",
        "                             verbose=1)\n",
        "\n",
        "# Train the model\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "history  = model.fit(X_teacher2, Y_train2, epochs=epochs, batch_size=batch_size,\n",
        "          validation_data=(X_test3, Y_test3), callbacks=[checkpoint])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "#%% Evaluate the model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model.keras')\n",
        "\n",
        "predicted_labels = model.predict(X_test3)\n",
        "y_pred = np.argmax(predicted_labels, axis = 1).astype(int)\n",
        "#y_pred = (predicted_labels >= .5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_mat = confusion_matrix(Y_test_teacher3, y_pred)\n",
        "\n",
        "# Compute precision, recall, and F1-score\n",
        "classification_rep = classification_report(Y_test_teacher3, y_pred)\n",
        "del model\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_uYZOiEEuh-G",
        "outputId": "8572112f-06ed-4e4c-d68d-7ae63d4d4ecc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.8750 - loss: 0.4176\n",
            "Epoch 1: val_loss improved from inf to 0.71479, saving model to best_model.keras\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.8464 - loss: 0.4244 - val_accuracy: 0.7285 - val_loss: 0.7148\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - accuracy: 0.8750 - loss: 0.3612\n",
            "Epoch 2: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8364 - loss: 0.4012 - val_accuracy: 0.7219 - val_loss: 0.7700\n",
            "Epoch 3/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8750 - loss: 0.3069\n",
            "Epoch 3: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8720 - loss: 0.3232 - val_accuracy: 0.7020 - val_loss: 0.8306\n",
            "Epoch 4/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - accuracy: 0.8750 - loss: 0.2823\n",
            "Epoch 4: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8724 - loss: 0.3274 - val_accuracy: 0.6821 - val_loss: 0.8765\n",
            "Epoch 5/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - accuracy: 0.8750 - loss: 0.2844\n",
            "Epoch 5: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8787 - loss: 0.3017 - val_accuracy: 0.6689 - val_loss: 0.9288\n",
            "Epoch 6/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9062 - loss: 0.3004\n",
            "Epoch 6: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8835 - loss: 0.2966 - val_accuracy: 0.6689 - val_loss: 0.9740\n",
            "Epoch 7/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - accuracy: 0.8125 - loss: 0.3709\n",
            "Epoch 7: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8448 - loss: 0.3197 - val_accuracy: 0.6689 - val_loss: 1.0061\n",
            "Epoch 8/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 171ms/step - accuracy: 0.8438 - loss: 0.4159\n",
            "Epoch 8: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8731 - loss: 0.3037 - val_accuracy: 0.6689 - val_loss: 1.0350\n",
            "Epoch 9/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9062 - loss: 0.2644\n",
            "Epoch 9: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8843 - loss: 0.2839 - val_accuracy: 0.6689 - val_loss: 1.0618\n",
            "Epoch 10/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9688 - loss: 0.1909\n",
            "Epoch 10: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8971 - loss: 0.2515 - val_accuracy: 0.6689 - val_loss: 1.0885\n",
            "Epoch 11/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - accuracy: 0.8750 - loss: 0.3087\n",
            "Epoch 11: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8767 - loss: 0.2793 - val_accuracy: 0.6689 - val_loss: 1.1147\n",
            "Epoch 12/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9062 - loss: 0.1609\n",
            "Epoch 12: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8838 - loss: 0.2546 - val_accuracy: 0.6755 - val_loss: 1.1341\n",
            "Epoch 13/30\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9060 - loss: 0.2419  \n",
            "Epoch 13: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9052 - loss: 0.2430 - val_accuracy: 0.6755 - val_loss: 1.1592\n",
            "Epoch 14/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9062 - loss: 0.2975\n",
            "Epoch 14: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9123 - loss: 0.2373 - val_accuracy: 0.6689 - val_loss: 1.1880\n",
            "Epoch 15/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.2319\n",
            "Epoch 15: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.2442 - val_accuracy: 0.6821 - val_loss: 1.1938\n",
            "Epoch 16/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8125 - loss: 0.3721\n",
            "Epoch 16: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.2758 - val_accuracy: 0.6821 - val_loss: 1.2094\n",
            "Epoch 17/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9062 - loss: 0.2305\n",
            "Epoch 17: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.2545 - val_accuracy: 0.6755 - val_loss: 1.2457\n",
            "Epoch 18/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.1901\n",
            "Epoch 18: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2112 - val_accuracy: 0.6821 - val_loss: 1.2556\n",
            "Epoch 19/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9375 - loss: 0.1457\n",
            "Epoch 19: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9302 - loss: 0.1955 - val_accuracy: 0.6821 - val_loss: 1.2709\n",
            "Epoch 20/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8750 - loss: 0.1910\n",
            "Epoch 20: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9177 - loss: 0.2109 - val_accuracy: 0.6755 - val_loss: 1.2897\n",
            "Epoch 21/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1274\n",
            "Epoch 21: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.1833 - val_accuracy: 0.6755 - val_loss: 1.3028\n",
            "Epoch 22/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9375 - loss: 0.2025\n",
            "Epoch 22: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9139 - loss: 0.2134 - val_accuracy: 0.6821 - val_loss: 1.3179\n",
            "Epoch 23/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8125 - loss: 0.4238\n",
            "Epoch 23: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8948 - loss: 0.2744 - val_accuracy: 0.6755 - val_loss: 1.3236\n",
            "Epoch 24/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9062 - loss: 0.2755\n",
            "Epoch 24: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2354 - val_accuracy: 0.6821 - val_loss: 1.3351\n",
            "Epoch 25/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.8438 - loss: 0.2743\n",
            "Epoch 25: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.2010 - val_accuracy: 0.6755 - val_loss: 1.3666\n",
            "Epoch 26/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9375 - loss: 0.1762\n",
            "Epoch 26: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9237 - loss: 0.1977 - val_accuracy: 0.6755 - val_loss: 1.3689\n",
            "Epoch 27/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9375 - loss: 0.1650\n",
            "Epoch 27: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9374 - loss: 0.1860 - val_accuracy: 0.6821 - val_loss: 1.3852\n",
            "Epoch 28/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9375 - loss: 0.2228\n",
            "Epoch 28: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2012 - val_accuracy: 0.6887 - val_loss: 1.4045\n",
            "Epoch 29/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0857\n",
            "Epoch 29: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9335 - loss: 0.1909 - val_accuracy: 0.6887 - val_loss: 1.4119\n",
            "Epoch 30/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9688 - loss: 0.1453\n",
            "Epoch 30: val_loss did not improve from 0.71479\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9226 - loss: 0.2020 - val_accuracy: 0.6954 - val_loss: 1.4308\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_6 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                               \u001b[38;5;34m672\u001b[0m \n",
              "\n",
              " dense_7 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                               \u001b[38;5;34m300\u001b[0m \n",
              "\n",
              " dense_8 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                                 \u001b[38;5;34m39\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> \n",
              "\n",
              " dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> \n",
              "\n",
              " dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,035\u001b[0m (11.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,035</span> (11.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,011\u001b[0m (3.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,011</span> (3.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,024\u001b[0m (7.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,024</span> (7.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7933122efeb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7933122efeb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Confusion Matrix:\n",
            "[[21  0 11]\n",
            " [ 1 12 25]\n",
            " [ 4  0 77]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.66      0.72        32\n",
            "         1.0       1.00      0.32      0.48        38\n",
            "         2.0       0.68      0.95      0.79        81\n",
            "\n",
            "    accuracy                           0.73       151\n",
            "   macro avg       0.83      0.64      0.67       151\n",
            "weighted avg       0.79      0.73      0.70       151\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Type 1,2 and 3 classification"
      ],
      "metadata": {
        "id": "rGZ68dO9-sIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='best_model.h5',  # File to save the best model\n",
        "                             monitor='val_loss',  # Monitor validation loss\n",
        "                             save_best_only=True,  # Save only the best model\n",
        "                             save_weights_only=False,  # Save the entire model (including architecture)\n",
        "                             mode='minx',  # Mode can be 'min' for loss or 'max' for accuracy\n",
        "                             verbose=1)\n",
        "\n",
        "# Train the model\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "history  = model.fit(X_teacher3, Y_train3, epochs=epochs, batch_size=batch_size,\n",
        "          validation_data=(X_test3, Y_test3), callbacks=[checkpoint])\n",
        "\n",
        "print(model.summary())\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "#%% Evaluate the model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "predicted_labels = model.predict(X_test3)\n",
        "y_pred = np.argmax(predicted_labels, axis = 1).astype(int)\n",
        "#y_pred = (predicted_labels >= .5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_mat = confusion_matrix(Y_test_teacher3, y_pred)\n",
        "\n",
        "# Compute precision, recall, and F1-score\n",
        "classification_rep = classification_report(Y_test_teacher3, y_pred)\n",
        "del model\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERYvrZ-VvgbG",
        "outputId": "d0f9c7da-4670-4f7f-b115-d60b60338169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:ModelCheckpoint mode minx is unknown, fallback to auto mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            " 1/19 [>.............................] - ETA: 14s - loss: 0.8525 - accuracy: 0.6250\n",
            "Epoch 1: val_loss improved from inf to 0.90377, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 1s 14ms/step - loss: 0.9965 - accuracy: 0.5209 - val_loss: 0.9038 - val_accuracy: 0.5430\n",
            "Epoch 2/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.9067 - accuracy: 0.6562\n",
            "Epoch 2: val_loss improved from 0.90377 to 0.83070, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.9049 - accuracy: 0.5459 - val_loss: 0.8307 - val_accuracy: 0.5695\n",
            "Epoch 3/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.9039 - accuracy: 0.5938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3: val_loss improved from 0.83070 to 0.77142, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.8401 - accuracy: 0.5776 - val_loss: 0.7714 - val_accuracy: 0.6225\n",
            "Epoch 4/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.8194 - accuracy: 0.6250\n",
            "Epoch 4: val_loss improved from 0.77142 to 0.72472, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.7834 - accuracy: 0.6477 - val_loss: 0.7247 - val_accuracy: 0.7219\n",
            "Epoch 5/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.8809 - accuracy: 0.5312\n",
            "Epoch 5: val_loss improved from 0.72472 to 0.66956, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.7321 - accuracy: 0.7262 - val_loss: 0.6696 - val_accuracy: 0.7748\n",
            "Epoch 6/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.6384 - accuracy: 0.7500\n",
            "Epoch 6: val_loss improved from 0.66956 to 0.61818, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.7679 - val_loss: 0.6182 - val_accuracy: 0.7815\n",
            "Epoch 7/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.7956 - accuracy: 0.6875\n",
            "Epoch 7: val_loss improved from 0.61818 to 0.56565, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.6302 - accuracy: 0.8013 - val_loss: 0.5657 - val_accuracy: 0.8079\n",
            "Epoch 8/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.5422 - accuracy: 0.7812\n",
            "Epoch 8: val_loss improved from 0.56565 to 0.51258, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5766 - accuracy: 0.8063 - val_loss: 0.5126 - val_accuracy: 0.8079\n",
            "Epoch 9/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.5639 - accuracy: 0.8125\n",
            "Epoch 9: val_loss improved from 0.51258 to 0.47669, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.5291 - accuracy: 0.8364 - val_loss: 0.4767 - val_accuracy: 0.8477\n",
            "Epoch 10/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.4427 - accuracy: 0.8438\n",
            "Epoch 10: val_loss improved from 0.47669 to 0.43545, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.8447 - val_loss: 0.4354 - val_accuracy: 0.8543\n",
            "Epoch 11/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.5639 - accuracy: 0.7812\n",
            "Epoch 11: val_loss improved from 0.43545 to 0.41099, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8447 - val_loss: 0.4110 - val_accuracy: 0.8543\n",
            "Epoch 12/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.4119 - accuracy: 0.8750\n",
            "Epoch 12: val_loss improved from 0.41099 to 0.39033, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.8598 - val_loss: 0.3903 - val_accuracy: 0.8609\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.8664\n",
            "Epoch 13: val_loss improved from 0.39033 to 0.37348, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8664 - val_loss: 0.3735 - val_accuracy: 0.8742\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8748\n",
            "Epoch 14: val_loss improved from 0.37348 to 0.35630, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3768 - accuracy: 0.8748 - val_loss: 0.3563 - val_accuracy: 0.8808\n",
            "Epoch 15/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.3189 - accuracy: 0.8750\n",
            "Epoch 15: val_loss improved from 0.35630 to 0.34865, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8715 - val_loss: 0.3487 - val_accuracy: 0.8742\n",
            "Epoch 16/30\n",
            "17/19 [=========================>....] - ETA: 0s - loss: 0.3579 - accuracy: 0.8713\n",
            "Epoch 16: val_loss improved from 0.34865 to 0.33956, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3421 - accuracy: 0.8815 - val_loss: 0.3396 - val_accuracy: 0.8742\n",
            "Epoch 17/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.3638 - accuracy: 0.8750\n",
            "Epoch 17: val_loss improved from 0.33956 to 0.32779, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3307 - accuracy: 0.8781 - val_loss: 0.3278 - val_accuracy: 0.8742\n",
            "Epoch 18/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.2962 - accuracy: 0.9375\n",
            "Epoch 18: val_loss improved from 0.32779 to 0.32105, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.3167 - accuracy: 0.8831 - val_loss: 0.3211 - val_accuracy: 0.8808\n",
            "Epoch 19/30\n",
            "15/19 [======================>.......] - ETA: 0s - loss: 0.3265 - accuracy: 0.8750\n",
            "Epoch 19: val_loss improved from 0.32105 to 0.31313, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.3045 - accuracy: 0.8865 - val_loss: 0.3131 - val_accuracy: 0.8940\n",
            "Epoch 20/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.1783 - accuracy: 0.9688\n",
            "Epoch 20: val_loss improved from 0.31313 to 0.31242, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2942 - accuracy: 0.8881 - val_loss: 0.3124 - val_accuracy: 0.8742\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.8865\n",
            "Epoch 21: val_loss improved from 0.31242 to 0.30367, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2876 - accuracy: 0.8865 - val_loss: 0.3037 - val_accuracy: 0.8874\n",
            "Epoch 22/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.3260 - accuracy: 0.8438\n",
            "Epoch 22: val_loss improved from 0.30367 to 0.30229, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 7ms/step - loss: 0.2777 - accuracy: 0.8898 - val_loss: 0.3023 - val_accuracy: 0.8808\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.8898\n",
            "Epoch 23: val_loss improved from 0.30229 to 0.29639, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2711 - accuracy: 0.8898 - val_loss: 0.2964 - val_accuracy: 0.9007\n",
            "Epoch 24/30\n",
            "18/19 [===========================>..] - ETA: 0s - loss: 0.2637 - accuracy: 0.9062\n",
            "Epoch 24: val_loss improved from 0.29639 to 0.29532, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2646 - accuracy: 0.9048 - val_loss: 0.2953 - val_accuracy: 0.8874\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.8982\n",
            "Epoch 25: val_loss improved from 0.29532 to 0.29215, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2578 - accuracy: 0.8982 - val_loss: 0.2922 - val_accuracy: 0.9007\n",
            "Epoch 26/30\n",
            "18/19 [===========================>..] - ETA: 0s - loss: 0.2506 - accuracy: 0.9080\n",
            "Epoch 26: val_loss improved from 0.29215 to 0.29050, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 8ms/step - loss: 0.2520 - accuracy: 0.9082 - val_loss: 0.2905 - val_accuracy: 0.9007\n",
            "Epoch 27/30\n",
            "17/19 [=========================>....] - ETA: 0s - loss: 0.2488 - accuracy: 0.8971\n",
            "Epoch 27: val_loss improved from 0.29050 to 0.28962, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 9ms/step - loss: 0.2460 - accuracy: 0.9015 - val_loss: 0.2896 - val_accuracy: 0.8808\n",
            "Epoch 28/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.1860 - accuracy: 0.9375\n",
            "Epoch 28: val_loss improved from 0.28962 to 0.28641, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.9098 - val_loss: 0.2864 - val_accuracy: 0.8808\n",
            "Epoch 29/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.1780 - accuracy: 0.9688\n",
            "Epoch 29: val_loss improved from 0.28641 to 0.28184, saving model to best_model_s2.h5\n",
            "19/19 [==============================] - 0s 5ms/step - loss: 0.2366 - accuracy: 0.9149 - val_loss: 0.2818 - val_accuracy: 0.8940\n",
            "Epoch 30/30\n",
            " 1/19 [>.............................] - ETA: 0s - loss: 0.4539 - accuracy: 0.8125\n",
            "Epoch 30: val_loss did not improve from 0.28184\n",
            "19/19 [==============================] - 0s 4ms/step - loss: 0.2311 - accuracy: 0.9132 - val_loss: 0.2851 - val_accuracy: 0.8808\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_44 (Flatten)        (None, 27)                0         \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 24)                672       \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 12)                300       \n",
            "                                                                 \n",
            " dense_134 (Dense)           (None, 3)                 39        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1011 (3.95 KB)\n",
            "Trainable params: 1011 (3.95 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "5/5 [==============================] - 0s 2ms/step\n",
            "Confusion Matrix:\n",
            "[[26  1  5]\n",
            " [ 0 36  2]\n",
            " [ 6  2 73]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.81      0.81        32\n",
            "         1.0       0.92      0.95      0.94        38\n",
            "         2.0       0.91      0.90      0.91        81\n",
            "\n",
            "    accuracy                           0.89       151\n",
            "   macro avg       0.88      0.89      0.88       151\n",
            "weighted avg       0.89      0.89      0.89       151\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RCL"
      ],
      "metadata": {
        "id": "HzR5kKgUAcdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate the initial data for training"
      ],
      "metadata": {
        "id": "t5J-WAJ32Iwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_abnormal_train = X_abnormal_train.shape[0]\n",
        "num_normal_train = X_normal_train.shape[0]\n",
        "\n",
        "import SMOTE\n",
        "# SMOTE for abnormal\n",
        "s1 = SMOTE.Smote(X_abnormal_train,N = 100)\n",
        "newdata_smote1 = np.unique(s1.over_sampling(),axis = 0)\n",
        "\n",
        "# SMOTE for normal\n",
        "s2 = SMOTE.Smote(X_normal_train,N = 100)\n",
        "newdata_smote2 = np.unique(s2.over_sampling(),axis = 0)\n",
        "\n",
        "# SMOTE for transition\n",
        "s3 = SMOTE.Smote(X_transition_train,N = 100)\n",
        "newdata_smote3 = np.unique(s3.over_sampling(),axis = 0)\n",
        "\n",
        "X_abnormal_train_new = newdata_smote1 + 0.0\n",
        "X_normal_train_new = newdata_smote2 + 0.0\n",
        "X_transition_train_new = newdata_smote3 + 0.0"
      ],
      "metadata": {
        "id": "PZzLgw392ILV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Distinguish the type 1,2 and 3"
      ],
      "metadata": {
        "id": "W9zeVpEZ4cju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_teacher1 = np.concatenate((X_normal_train_new,X_abnormal_train))\n",
        "Y_teacher1 = np.concatenate((np.expand_dims(Y_normal_train, axis = 1), np.expand_dims(Y_abnormal_train, axis = 1)), axis = 0)\n",
        "Y_teacher1 = Y_teacher1.reshape(-1)\n",
        "Y_train1 = Y_teacher1 + 0\n",
        "\n",
        "X_test1 = np.concatenate((X_normal_test, X_abnormal_test))\n",
        "Y_test_teacher1 = np.concatenate((np.expand_dims(Y_normal_test, axis = 1), np.expand_dims(Y_abnormal_test, axis = 1)), axis = 0)\n",
        "Y_test_teacher1 = Y_test_teacher1.reshape(-1)\n",
        "Y_test1 = Y_test_teacher1 + 0\n",
        "\n",
        "X_teacher2 = np.concatenate((X_normal_train_new,X_transition_train))\n",
        "Y_teacher2 = np.concatenate((np.expand_dims(Y_normal_train, axis = 1), np.expand_dims(Y_transition_train, axis = 1)), axis = 0)\n",
        "Y_teacher2 = Y_teacher2.reshape(-1)\n",
        "Y_train2 = Y_teacher2 + 0\n",
        "\n",
        "X_test2 = np.concatenate((X_normal_test, X_transition_test))\n",
        "Y_test_teacher2 = np.concatenate((np.expand_dims(Y_normal_test, axis = 1), np.expand_dims(Y_transition_test, axis = 1)), axis = 0)\n",
        "Y_test_teacher2 = Y_test_teacher2.reshape(-1)\n",
        "Y_test2 = Y_test_teacher2 + 0\n",
        "\n",
        "X_teacher3 = np.concatenate((X_normal_train_new,X_abnormal_train_new,X_transition_train))\n",
        "\n",
        "Y_teacher3 = np.concatenate((np.expand_dims(Y_normal_train, axis = 1), np.expand_dims(Y_abnormal_train, axis = 1),np.expand_dims(Y_transition_train, axis = 1)), axis = 0)\n",
        "Y_teacher3 = Y_teacher3.reshape(-1)\n",
        "Y_train3 = Y_teacher3 + 0\n",
        "\n",
        "X_test3 = np.concatenate((X_normal_test, X_abnormal_test,X_transition_test))\n",
        "Y_test_teacher3 = np.concatenate((np.expand_dims(Y_normal_test, axis = 1), np.expand_dims(Y_abnormal_test, axis = 1),np.expand_dims(Y_transition_test, axis = 1)), axis = 0)\n",
        "Y_test_teacher3 = Y_test_teacher3.reshape(-1)\n",
        "Y_test3 = Y_test_teacher3 + 0\n"
      ],
      "metadata": {
        "id": "rY4ALZ95204Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Do the classification"
      ],
      "metadata": {
        "id": "tyA2IA2N4h9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='best_model2.keras',  # File to save the best model\n",
        "                             monitor='val_loss',  # Monitor validation loss\n",
        "                             save_best_only=True,  # Save only the best model\n",
        "                             save_weights_only=False,  # Save the entire model (including architecture)\n",
        "                             mode='min',  # Mode can be 'min' for loss or 'max' for accuracy\n",
        "                             verbose=1)\n",
        "\n",
        "# Train the model\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "history  = model.fit(X_teacher1, Y_train1, epochs=epochs, batch_size=batch_size,\n",
        "          validation_data=(X_test1, Y_test1), callbacks=[checkpoint])\n",
        "\n",
        "print(model.summary())\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "#%% Evaluate the model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model2.keras')\n",
        "\n",
        "predicted_labels = model.predict(X_test1)\n",
        "y_pred = np.argmax(predicted_labels, axis = 1).astype(int)\n",
        "#y_pred = (predicted_labels >= .5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_mat = confusion_matrix(Y_test_teacher1, y_pred)\n",
        "\n",
        "# Compute precision, recall, and F1-score\n",
        "classification_rep = classification_report(Y_test_teacher1, y_pred)\n",
        "del model\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c_vqRjQ3v8ms",
        "outputId": "dae3adaa-663b-46b7-9e86-c0cc80a7fca4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.3125 - loss: 1.5884\n",
            "Epoch 1: val_loss improved from inf to 1.08649, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4942 - loss: 1.2542 - val_accuracy: 0.5286 - val_loss: 1.0865\n",
            "Epoch 2/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 1.0865\n",
            "Epoch 2: val_loss improved from 1.08649 to 0.94952, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5478 - loss: 1.0491 - val_accuracy: 0.5429 - val_loss: 0.9495\n",
            "Epoch 3/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 0.5312 - loss: 0.9277\n",
            "Epoch 3: val_loss improved from 0.94952 to 0.82651, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6013 - loss: 0.8962 - val_accuracy: 0.5857 - val_loss: 0.8265\n",
            "Epoch 4/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 183ms/step - accuracy: 0.6562 - loss: 0.7752\n",
            "Epoch 4: val_loss improved from 0.82651 to 0.70225, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6431 - loss: 0.8007 - val_accuracy: 0.7286 - val_loss: 0.7023\n",
            "Epoch 5/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.7188 - loss: 0.6757\n",
            "Epoch 5: val_loss improved from 0.70225 to 0.59218, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7566 - loss: 0.6735 - val_accuracy: 0.8714 - val_loss: 0.5922\n",
            "Epoch 6/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9062 - loss: 0.5184\n",
            "Epoch 6: val_loss improved from 0.59218 to 0.49577, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8642 - loss: 0.5536 - val_accuracy: 0.9714 - val_loss: 0.4958\n",
            "Epoch 7/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.8125 - loss: 0.5517\n",
            "Epoch 7: val_loss improved from 0.49577 to 0.41400, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9010 - loss: 0.4857 - val_accuracy: 0.9714 - val_loss: 0.4140\n",
            "Epoch 8/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9062 - loss: 0.4434\n",
            "Epoch 8: val_loss improved from 0.41400 to 0.34558, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9230 - loss: 0.4137 - val_accuracy: 0.9714 - val_loss: 0.3456\n",
            "Epoch 9/30\n",
            "\u001b[1m8/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9351 - loss: 0.3542  \n",
            "Epoch 9: val_loss improved from 0.34558 to 0.29185, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9337 - loss: 0.3503 - val_accuracy: 0.9714 - val_loss: 0.2918\n",
            "Epoch 10/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9375 - loss: 0.2817\n",
            "Epoch 10: val_loss improved from 0.29185 to 0.24983, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9363 - loss: 0.2867 - val_accuracy: 0.9857 - val_loss: 0.2498\n",
            "Epoch 11/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 154ms/step - accuracy: 0.9375 - loss: 0.3002\n",
            "Epoch 11: val_loss improved from 0.24983 to 0.21631, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9348 - loss: 0.2615 - val_accuracy: 0.9857 - val_loss: 0.2163\n",
            "Epoch 12/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 0.9062 - loss: 0.2842\n",
            "Epoch 12: val_loss improved from 0.21631 to 0.18959, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9393 - loss: 0.2264 - val_accuracy: 0.9857 - val_loss: 0.1896\n",
            "Epoch 13/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 0.3416\n",
            "Epoch 13: val_loss improved from 0.18959 to 0.16871, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9189 - loss: 0.2332 - val_accuracy: 0.9857 - val_loss: 0.1687\n",
            "Epoch 14/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9688 - loss: 0.1500\n",
            "Epoch 14: val_loss improved from 0.16871 to 0.15311, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9484 - loss: 0.1828 - val_accuracy: 0.9857 - val_loss: 0.1531\n",
            "Epoch 15/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1296\n",
            "Epoch 15: val_loss improved from 0.15311 to 0.13950, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9726 - loss: 0.1547 - val_accuracy: 0.9857 - val_loss: 0.1395\n",
            "Epoch 16/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9375 - loss: 0.1920\n",
            "Epoch 16: val_loss improved from 0.13950 to 0.12874, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9543 - loss: 0.1608 - val_accuracy: 0.9857 - val_loss: 0.1287\n",
            "Epoch 17/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9688 - loss: 0.1438\n",
            "Epoch 17: val_loss improved from 0.12874 to 0.12047, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9626 - loss: 0.1462 - val_accuracy: 0.9857 - val_loss: 0.1205\n",
            "Epoch 18/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9375 - loss: 0.1813\n",
            "Epoch 18: val_loss improved from 0.12047 to 0.11193, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9591 - loss: 0.1463 - val_accuracy: 0.9857 - val_loss: 0.1119\n",
            "Epoch 19/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9688 - loss: 0.1347\n",
            "Epoch 19: val_loss improved from 0.11193 to 0.10547, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.1227 - val_accuracy: 0.9857 - val_loss: 0.1055\n",
            "Epoch 20/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9375 - loss: 0.2006\n",
            "Epoch 20: val_loss improved from 0.10547 to 0.09841, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9603 - loss: 0.1444 - val_accuracy: 0.9857 - val_loss: 0.0984\n",
            "Epoch 21/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9688 - loss: 0.1156\n",
            "Epoch 21: val_loss improved from 0.09841 to 0.09323, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9755 - loss: 0.1094 - val_accuracy: 0.9857 - val_loss: 0.0932\n",
            "Epoch 22/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0800\n",
            "Epoch 22: val_loss improved from 0.09323 to 0.08766, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9866 - loss: 0.0956 - val_accuracy: 0.9857 - val_loss: 0.0877\n",
            "Epoch 23/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9688 - loss: 0.1295\n",
            "Epoch 23: val_loss improved from 0.08766 to 0.08244, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9824 - loss: 0.0998 - val_accuracy: 0.9857 - val_loss: 0.0824\n",
            "Epoch 24/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0471\n",
            "Epoch 24: val_loss improved from 0.08244 to 0.07983, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9838 - loss: 0.0801 - val_accuracy: 0.9857 - val_loss: 0.0798\n",
            "Epoch 25/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9688 - loss: 0.1475\n",
            "Epoch 25: val_loss improved from 0.07983 to 0.07460, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9821 - loss: 0.0990 - val_accuracy: 0.9857 - val_loss: 0.0746\n",
            "Epoch 26/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0383\n",
            "Epoch 26: val_loss improved from 0.07460 to 0.07232, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9825 - loss: 0.0735 - val_accuracy: 0.9857 - val_loss: 0.0723\n",
            "Epoch 27/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9688 - loss: 0.0847\n",
            "Epoch 27: val_loss improved from 0.07232 to 0.07052, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0780 - val_accuracy: 0.9857 - val_loss: 0.0705\n",
            "Epoch 28/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0424\n",
            "Epoch 28: val_loss improved from 0.07052 to 0.06642, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9763 - loss: 0.0796 - val_accuracy: 0.9857 - val_loss: 0.0664\n",
            "Epoch 29/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9688 - loss: 0.0912\n",
            "Epoch 29: val_loss improved from 0.06642 to 0.06326, saving model to best_model2.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9787 - loss: 0.0743 - val_accuracy: 0.9857 - val_loss: 0.0633\n",
            "Epoch 30/30\n",
            "\u001b[1m1/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9688 - loss: 0.0739\n",
            "Epoch 30: val_loss did not improve from 0.06326\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9809 - loss: 0.0724 - val_accuracy: 0.9857 - val_loss: 0.0640\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_12 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                               \u001b[38;5;34m672\u001b[0m \n",
              "\n",
              " dense_13 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                               \u001b[38;5;34m300\u001b[0m \n",
              "\n",
              " dense_14 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                                 \u001b[38;5;34m39\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> \n",
              "\n",
              " dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> \n",
              "\n",
              " dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,035\u001b[0m (11.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,035</span> (11.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,011\u001b[0m (3.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,011</span> (3.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,024\u001b[0m (7.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,024</span> (7.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Confusion Matrix:\n",
            "[[31  1]\n",
            " [ 0 38]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.97      0.98        32\n",
            "         1.0       0.97      1.00      0.99        38\n",
            "\n",
            "    accuracy                           0.99        70\n",
            "   macro avg       0.99      0.98      0.99        70\n",
            "weighted avg       0.99      0.99      0.99        70\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#    from keras.layers.normalization import LayerNormalization\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model2.keras')\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(filepath='best_model2.keras',  # File to save the best model\n",
        "                             monitor='val_loss',  # Monitor validation loss\n",
        "                             save_best_only=True,  # Save only the best model\n",
        "                             save_weights_only=False,  # Save the entire model (including architecture)\n",
        "                             mode='min',  # Mode can be 'min' for loss or 'max' for accuracy\n",
        "                             verbose=1)\n",
        "\n",
        "# Train the model\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "history  = model.fit(X_teacher2, Y_train2, epochs=epochs, batch_size=batch_size,\n",
        "          validation_data=(X_test3, Y_test3), callbacks=[checkpoint])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "#%% Evaluate the model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model2.keras')\n",
        "\n",
        "predicted_labels = model.predict(X_test3)\n",
        "y_pred = np.argmax(predicted_labels, axis = 1).astype(int)\n",
        "#y_pred = (predicted_labels >= .5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "confusion_mat = confusion_matrix(Y_test_teacher3, y_pred)\n",
        "\n",
        "# Compute precision, recall, and F1-score\n",
        "classification_rep = classification_report(Y_test_teacher3, y_pred)\n",
        "del model\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qeMdi3eiA5p1",
        "outputId": "83306857-262e-40eb-9f08-1b8d7bb44eb7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 795ms/step - accuracy: 0.2500 - loss: 2.9159\n",
            "Epoch 1: val_loss improved from inf to 1.13046, saving model to best_model2.keras\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2701 - loss: 2.6300 - val_accuracy: 0.4503 - val_loss: 1.1305\n",
            "Epoch 2/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3125 - loss: 1.4836\n",
            "Epoch 2: val_loss improved from 1.13046 to 0.57452, saving model to best_model2.keras\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3497 - loss: 1.3102 - val_accuracy: 0.7616 - val_loss: 0.5745\n",
            "Epoch 3/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5625 - loss: 0.8593\n",
            "Epoch 3: val_loss improved from 0.57452 to 0.50611, saving model to best_model2.keras\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6461 - loss: 0.7104 - val_accuracy: 0.7815 - val_loss: 0.5061\n",
            "Epoch 4/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 195ms/step - accuracy: 0.8438 - loss: 0.4425\n",
            "Epoch 4: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.4545 - val_accuracy: 0.6887 - val_loss: 0.6190\n",
            "Epoch 5/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8750 - loss: 0.3598\n",
            "Epoch 5: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8523 - loss: 0.4172 - val_accuracy: 0.6755 - val_loss: 0.7161\n",
            "Epoch 6/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9375 - loss: 0.3192\n",
            "Epoch 6: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8830 - loss: 0.3885 - val_accuracy: 0.6755 - val_loss: 0.7940\n",
            "Epoch 7/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.2273\n",
            "Epoch 7: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8707 - loss: 0.3411 - val_accuracy: 0.6821 - val_loss: 0.8707\n",
            "Epoch 8/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9062 - loss: 0.2482\n",
            "Epoch 8: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8744 - loss: 0.3023 - val_accuracy: 0.6821 - val_loss: 0.9313\n",
            "Epoch 9/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8125 - loss: 0.4021\n",
            "Epoch 9: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.3321 - val_accuracy: 0.6689 - val_loss: 0.9852\n",
            "Epoch 10/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.2803\n",
            "Epoch 10: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8677 - loss: 0.3061 - val_accuracy: 0.6689 - val_loss: 1.0299\n",
            "Epoch 11/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8125 - loss: 0.3787\n",
            "Epoch 11: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8783 - loss: 0.3091 - val_accuracy: 0.6755 - val_loss: 1.0796\n",
            "Epoch 12/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9062 - loss: 0.2729\n",
            "Epoch 12: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9059 - loss: 0.2709 - val_accuracy: 0.6689 - val_loss: 1.1218\n",
            "Epoch 13/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8438 - loss: 0.3705\n",
            "Epoch 13: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2709 - val_accuracy: 0.6623 - val_loss: 1.1598\n",
            "Epoch 14/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9062 - loss: 0.2236\n",
            "Epoch 14: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8994 - loss: 0.2667 - val_accuracy: 0.6623 - val_loss: 1.1932\n",
            "Epoch 15/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9688 - loss: 0.1560\n",
            "Epoch 15: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2292 - val_accuracy: 0.6689 - val_loss: 1.2383\n",
            "Epoch 16/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9062 - loss: 0.3715\n",
            "Epoch 16: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.2788 - val_accuracy: 0.6623 - val_loss: 1.2501\n",
            "Epoch 17/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8750 - loss: 0.2370\n",
            "Epoch 17: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.2411 - val_accuracy: 0.6623 - val_loss: 1.2841\n",
            "Epoch 18/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8750 - loss: 0.2718\n",
            "Epoch 18: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9081 - loss: 0.2428 - val_accuracy: 0.6689 - val_loss: 1.3149\n",
            "Epoch 19/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8750 - loss: 0.3877\n",
            "Epoch 19: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2544 - val_accuracy: 0.6689 - val_loss: 1.3340\n",
            "Epoch 20/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9062 - loss: 0.2108\n",
            "Epoch 20: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9187 - loss: 0.2261 - val_accuracy: 0.6689 - val_loss: 1.3846\n",
            "Epoch 21/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9688 - loss: 0.2117\n",
            "Epoch 21: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9365 - loss: 0.2151 - val_accuracy: 0.6689 - val_loss: 1.3950\n",
            "Epoch 22/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9375 - loss: 0.2082\n",
            "Epoch 22: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9286 - loss: 0.2071 - val_accuracy: 0.6689 - val_loss: 1.4055\n",
            "Epoch 23/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8750 - loss: 0.3453\n",
            "Epoch 23: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9098 - loss: 0.2376 - val_accuracy: 0.6689 - val_loss: 1.4292\n",
            "Epoch 24/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9375 - loss: 0.2148\n",
            "Epoch 24: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9295 - loss: 0.2081 - val_accuracy: 0.6689 - val_loss: 1.4509\n",
            "Epoch 25/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9375 - loss: 0.2826\n",
            "Epoch 25: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.2220 - val_accuracy: 0.6755 - val_loss: 1.4761\n",
            "Epoch 26/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9062 - loss: 0.2771\n",
            "Epoch 26: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9356 - loss: 0.2024 - val_accuracy: 0.6755 - val_loss: 1.5093\n",
            "Epoch 27/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9375 - loss: 0.1528\n",
            "Epoch 27: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9301 - loss: 0.1879 - val_accuracy: 0.6689 - val_loss: 1.4977\n",
            "Epoch 28/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9688 - loss: 0.1008\n",
            "Epoch 28: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9287 - loss: 0.1916 - val_accuracy: 0.6755 - val_loss: 1.5344\n",
            "Epoch 29/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8750 - loss: 0.2565\n",
            "Epoch 29: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9306 - loss: 0.1898 - val_accuracy: 0.6689 - val_loss: 1.5626\n",
            "Epoch 30/30\n",
            "\u001b[1m 1/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 0.1100\n",
            "Epoch 30: val_loss did not improve from 0.50611\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9425 - loss: 0.1626 - val_accuracy: 0.6755 - val_loss: 1.5850\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_12 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                               \u001b[38;5;34m672\u001b[0m \n",
              "\n",
              " dense_13 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)                               \u001b[38;5;34m300\u001b[0m \n",
              "\n",
              " dense_14 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                                 \u001b[38;5;34m39\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> \n",
              "\n",
              " dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> \n",
              "\n",
              " dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,035\u001b[0m (11.86 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,035</span> (11.86 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,011\u001b[0m (3.95 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,011</span> (3.95 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,024\u001b[0m (7.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,024</span> (7.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Confusion Matrix:\n",
            "[[21  0 11]\n",
            " [ 1 28  9]\n",
            " [ 4  8 69]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.66      0.72        32\n",
            "         1.0       0.78      0.74      0.76        38\n",
            "         2.0       0.78      0.85      0.81        81\n",
            "\n",
            "    accuracy                           0.78       151\n",
            "   macro avg       0.79      0.75      0.76       151\n",
            "weighted avg       0.78      0.78      0.78       151\n",
            "\n"
          ]
        }
      ]
    }
  ]
}